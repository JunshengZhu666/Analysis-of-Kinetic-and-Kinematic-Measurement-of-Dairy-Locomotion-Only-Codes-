{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67f43dae",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246bbc43",
   "metadata": {},
   "source": [
    "### Load into X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca114d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "############## read in kinetic data ##################################\n",
    "#####################################################################\n",
    "\n",
    "## read in kinetic data \n",
    "## into shape \n",
    "## x_train:  (data size, rows, columns)\n",
    "## x_test:  (data size, rows, columns)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import glob\n",
    "#import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# list of names of files \n",
    "file_names = []\n",
    "# X is the data before preprocess\n",
    "X = np.zeros((70, 70, 50))\n",
    "# load in every excel file from kinetic_processed\n",
    "for i, xls_file in enumerate(glob.glob(\"kinetic_processed/*\")):\n",
    "    # append into file_names list\n",
    "    file_names.append(xls_file)\n",
    "    #print(xls_file)\n",
    "    # exclude column index and create panda dataframe\n",
    "    dataframe = pd.read_excel(xls_file).iloc[:, 1:]\n",
    "    # convert into numpy array and store into X\n",
    "    matrix = dataframe.to_numpy()\n",
    "    #print(matrix.shape)\n",
    "    X[i] = matrix\n",
    "    \n",
    "print(\"total number of examples: \", X.shape[0])\n",
    "print(\"dimension of one examples: \", X.shape[1], X.shape[2])\n",
    "print(\"obtain array X with shape: \", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fddfeb2",
   "metadata": {},
   "source": [
    "### Load in Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5401a2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of Y:  70\n",
      "any null data:  False\n",
      "X.shape:  (66, 70, 50)\n",
      "Y.shape:  (66,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## load in excel file\n",
    "\n",
    "# name of the label file \n",
    "excel_name = 'labels.xlsx'\n",
    "# read in by panda\n",
    "df = pd.read_excel(excel_name)\n",
    "# only need the second column, where we store the score\n",
    "Y = df.iloc[:, 2]\n",
    "\n",
    "print(\"the length of Y: \", len(Y))\n",
    "print(\"any null data: \", (Y==None).any())\n",
    "\n",
    "## clean some missing data where we labeled -1  and display the label distribution \n",
    "\n",
    "# store our original data\n",
    "X_temp = X\n",
    "Y_temp = Y\n",
    "\n",
    "# exclude the missing data, where I put -1 for NRS, \n",
    "X_clean = []\n",
    "Y_clean = []\n",
    "\n",
    "# if labeled as -1, not append that example/label\n",
    "for i, j in enumerate(Y): \n",
    "    if j == -1: \n",
    "        pass \n",
    "    else: \n",
    "        X_clean.append(X[i])\n",
    "        Y_clean.append(Y[i])\n",
    "\n",
    "# store as numpy array and inspect the shape as X and Y\n",
    "X = np.array(X_clean)\n",
    "Y = np.array(Y_clean)\n",
    "print(\"X.shape: \", X.shape) \n",
    "print(\"Y.shape: \", Y.shape)\n",
    "\n",
    "# plot to see the distribution \n",
    "data = Y\n",
    "plt.xlim([min(data)-1, max(data)+1])\n",
    "plt.hist(data, alpha=0.5)\n",
    "plt.title('Our label Y')\n",
    "plt.xlabel('NRS')\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07dd3a3",
   "metadata": {},
   "source": [
    "### Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "250ed861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      "-------------------------\n",
      "shape:  (66, 70, 50)\n",
      "min():  0.0\n",
      "max():  2970.0\n",
      "mean():  9.889324675324675\n",
      "std():  43.13761616171395\n",
      "-------------------------\n",
      "X_nor: \n",
      "-------------------------\n",
      "shape:  (66, 70, 50)\n",
      "min():  0.0\n",
      "max():  1.0\n",
      "mean():  0.0033297389479207662\n",
      "std():  0.014524449886098975\n",
      "-------------------------\n",
      "X_std: \n",
      "-------------------------\n",
      "shape:  (66, 70, 50)\n",
      "min():  0.0\n",
      "max():  68.84942340963134\n",
      "mean():  0.2292506066689373\n",
      "std():  1.0\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## function to inspect dataset X\n",
    "def inspect_stat(X):\n",
    "    print(\"-------------------------\")\n",
    "    print(\"shape: \", X.shape)\n",
    "    print(\"min(): \", X.min())\n",
    "    print(\"max(): \", X.max())\n",
    "    print(\"mean(): \", X.mean())\n",
    "    print(\"std(): \", X.std())\n",
    "    print(\"-------------------------\")\n",
    "\n",
    "# normalize dataset X into X_nor \n",
    "X_nor = X / X.max() \n",
    "\n",
    "# standardize dataset X \n",
    "X_temp = X - X.min() \n",
    "X_std = X_temp / X.std()\n",
    "\n",
    "\n",
    "# inspect dataset X \n",
    "print(\"X: \")\n",
    "inspect_stat(X)\n",
    "# inspect dataset X_nor \n",
    "print(\"X_nor: \")\n",
    "inspect_stat(X_nor)\n",
    "# inspect dataset X_std \n",
    "print(\"X_std: \")\n",
    "inspect_stat(X_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70326bb9",
   "metadata": {},
   "source": [
    "### Create Bi_Y from Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b318c47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([2.0, 2.5, 3.0, 1.5, 1.0, 3.5])\n",
      "dict_values([28, 11, 6, 16, 3, 2])\n",
      "bi_Y:  66 [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "dict_keys([0, 1])\n",
      "dict_values([58, 8])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## func to print the number for different scores \n",
    "from collections import Counter\n",
    "def inspect_y(y): \n",
    "    print(Counter(y).keys()) # equals to list(set(words))\n",
    "    print(Counter(y).values()) # counts the elements' frequency\n",
    "    \n",
    "# inspect value and their count in Y \n",
    "inspect_y(Y)\n",
    "\n",
    "## make Y a binary list \n",
    "# if NRS score is higher than 2.5, make it 1 (lameness) \n",
    "# else, make it 0 (non-lameness)\n",
    "def binarize(y): \n",
    "    b = [] \n",
    "    for i in y: \n",
    "        if i > 2.5: \n",
    "            b.append(1) \n",
    "        elif i <= 2.5: \n",
    "            b.append(0) \n",
    "        else: \n",
    "            return \"invalid number\"\n",
    "    return b \n",
    "\n",
    "# binarize y \n",
    "bi_Y = binarize(Y)\n",
    "print(\"bi_Y: \", len(bi_Y), bi_Y)\n",
    "inspect_y(bi_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2645b08",
   "metadata": {},
   "source": [
    "### Create Ti_Y from Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "254e5a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ti_Y:  66 [1, 2, 2, 1, 0, 2, 1, 0, 1, 1, 2, 1, 0, 1, 1, 2, 1, 0, 0, 0, 2, 1, 2, 2, 1, 2, 0, 0, 1, 1, 1, 1, 0, 1, 0, 2, 0, 0, 1, 1, 2, 0, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 0, 1, 0, 0, 0, 2, 0, 1, 1, 2, 2, 0, 2]\n",
      "Ti_Y:  (66, 3)\n"
     ]
    }
   ],
   "source": [
    "## try to make three categories \n",
    "# 1: 1.0, 1.5 (18)\n",
    "# 2: 2.0 (28) \n",
    "# 3: 2.5, 3.0, 3.5 (19)\n",
    "\n",
    "def tri(y): \n",
    "    tri_y = [] \n",
    "    for i in y: \n",
    "        if i == 1.0 or i == 1.5: \n",
    "            tri_y.append(0) \n",
    "        elif i == 2.0: \n",
    "            tri_y.append(1) \n",
    "        elif i == 2.5 or i == 3.0 or i == 3.5: \n",
    "            tri_y.append(2) \n",
    "        else: \n",
    "            return \"invalida number\"\n",
    "    return tri_y \n",
    "\n",
    "# tri y \n",
    "Ti_Y = tri(Y)\n",
    "print(\"Ti_Y: \", len(Ti_Y), Ti_Y)\n",
    "\n",
    "# categorize Ti_Y: this is required by tf\n",
    "from keras.utils import to_categorical\n",
    "Ti_Y = to_categorical(Ti_Y)\n",
    "print(\"Ti_Y: \", Ti_Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8622a662",
   "metadata": {},
   "source": [
    "### Split into x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79f05756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 70, 50, 1)\n",
      "(20, 70, 50, 1)\n",
      "(46,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    ## INPUT X\n",
    "    X_std, \n",
    "    ## INPUT Y\n",
    "    np.array(bi_Y), \n",
    "    ## SPLIT RATIO\n",
    "    test_size=0.30, \n",
    "    random_state=1234)\n",
    "\n",
    "# expand dimension\n",
    "import tensorflow as tf\n",
    "x_train = tf.expand_dims(x_train, 3)\n",
    "x_test = tf.expand_dims(x_test, 3)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da755d62",
   "metadata": {},
   "source": [
    "# Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eb0973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization as BN\n",
    "from keras import backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e96cc399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 70, 50, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 70, 50, 2)         10        \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 70, 50, 4)         36        \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 70, 50, 4)        16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 35, 25, 4)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3500)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               448128    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 449,231\n",
      "Trainable params: 449,223\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"remember to change last unit, activation function and loss metric if switch binary to categorical classification\"\"\"\n",
    "\n",
    "# init input\n",
    "input = Input(shape=(70, 50, 1))\n",
    "\n",
    "\"\"\"conv\"\"\"\n",
    "layer = Conv2D(2, (2, 2), activation='relu', padding='same')(input)\n",
    "layer = Conv2D(4, (2, 2), activation='relu', padding='same')(layer)\n",
    "layer = BN()(layer)\n",
    "#layer = Conv2D(16, (4, 4), activation='relu', padding='same')(layer)\n",
    "#layer = BN()(layer)\n",
    "layer = MaxPooling2D(pool_size=(2,2))(layer)\n",
    "\n",
    "\"\"\"flatten and dense\"\"\"\n",
    "layer = Flatten()(layer)\n",
    "#layer = Dense(512, activation='relu')(layer)\n",
    "#layer = Dropout(0.2)(layer)\n",
    "layer = Dense(128, activation='relu')(layer)\n",
    "#layer = Dropout(0.2)(layer)\n",
    "layer = Dense(8, activation='relu')(layer)\n",
    "layer = Dense(1, activation='sigmoid')(layer)\n",
    "\n",
    "# init model and plot summary\n",
    "model = Model([input], layer)\n",
    "model.summary()\n",
    "\n",
    "# compile model \n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              # define loss metric\n",
    "              loss=keras.losses.binary_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304a5584",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7588dfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.3393 - val_accuracy: 0.9000\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9000\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9000\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9000\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9000\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3397 - val_accuracy: 0.9000\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9000\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9000\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9000\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9000\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 8.0684e-04 - accuracy: 1.0000 - val_loss: 0.3422 - val_accuracy: 0.9000\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 7.3204e-04 - accuracy: 1.0000 - val_loss: 0.3429 - val_accuracy: 0.9000\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 5.0667e-04 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.9000\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.9000\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.5836e-04 - accuracy: 1.0000 - val_loss: 0.3450 - val_accuracy: 0.9000\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.3159e-04 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.9000\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.9507e-04 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.9000\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 2.2711e-04 - accuracy: 1.0000 - val_loss: 0.3477 - val_accuracy: 0.9000\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 2.4611e-04 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9000\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.0221e-04 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9000\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.1304e-04 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 0.9000\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.7175e-04 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9000\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.9195e-04 - accuracy: 1.0000 - val_loss: 0.3536 - val_accuracy: 0.9000\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.5430e-04 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9000\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.4588e-04 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.9000\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.5720e-04 - accuracy: 1.0000 - val_loss: 0.3578 - val_accuracy: 0.9000\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.2953e-04 - accuracy: 1.0000 - val_loss: 0.3594 - val_accuracy: 0.9000\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.3440e-04 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.9000\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.2338e-04 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.9000\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1645e-04 - accuracy: 1.0000 - val_loss: 0.3643 - val_accuracy: 0.9000\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.3531e-04 - accuracy: 1.0000 - val_loss: 0.3660 - val_accuracy: 0.9000\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.0589e-04 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9000\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 9.9954e-05 - accuracy: 1.0000 - val_loss: 0.3696 - val_accuracy: 0.9000\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0932e-04 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.9000\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9.7704e-05 - accuracy: 1.0000 - val_loss: 0.3735 - val_accuracy: 0.9000\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 9.5926e-05 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.9000\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 8.6497e-05 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.9000\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 8.9857e-05 - accuracy: 1.0000 - val_loss: 0.3796 - val_accuracy: 0.9000\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 9.5812e-05 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.9000\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 8.6511e-05 - accuracy: 1.0000 - val_loss: 0.3839 - val_accuracy: 0.9000\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 9.1179e-05 - accuracy: 1.0000 - val_loss: 0.3861 - val_accuracy: 0.9000\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 7.8064e-05 - accuracy: 1.0000 - val_loss: 0.3884 - val_accuracy: 0.9000\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 9.2330e-05 - accuracy: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.9000\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 7.8898e-05 - accuracy: 1.0000 - val_loss: 0.3929 - val_accuracy: 0.9000\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 8.0603e-05 - accuracy: 1.0000 - val_loss: 0.3951 - val_accuracy: 0.9000\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.8345e-05 - accuracy: 1.0000 - val_loss: 0.3974 - val_accuracy: 0.9000\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 7.3195e-05 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.9000\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.8756e-05 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.9000\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 7.0155e-05 - accuracy: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.9000\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.6303e-05 - accuracy: 1.0000 - val_loss: 0.4070 - val_accuracy: 0.9000\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 6.7876e-05 - accuracy: 1.0000 - val_loss: 0.4095 - val_accuracy: 0.9000\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 6.7040e-05 - accuracy: 1.0000 - val_loss: 0.4120 - val_accuracy: 0.9000\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 6.7226e-05 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.9000\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 6.3096e-05 - accuracy: 1.0000 - val_loss: 0.4170 - val_accuracy: 0.9000\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.0189e-05 - accuracy: 1.0000 - val_loss: 0.4197 - val_accuracy: 0.9000\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 6.1570e-05 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.9000\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 7.0991e-05 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.1073e-05 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.9000\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.8131e-05 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.9000\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 5.2468e-05 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.9000\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 6.2798e-05 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.9000\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 5.2759e-05 - accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.9000\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 5.0989e-05 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.9000\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 4.9471e-05 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.9000\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 4.7141e-05 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.9000\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 6.1741e-05 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.9000\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 4.6990e-05 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9000\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 4.6873e-05 - accuracy: 1.0000 - val_loss: 0.4566 - val_accuracy: 0.9000\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 5.0910e-05 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.9000\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 4.8140e-05 - accuracy: 1.0000 - val_loss: 0.4629 - val_accuracy: 0.9000\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 4.2809e-05 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.9000\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 4.4798e-05 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.9000\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 4.3230e-05 - accuracy: 1.0000 - val_loss: 0.4723 - val_accuracy: 0.9000\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 4.1938e-05 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.9000\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 4.2631e-05 - accuracy: 1.0000 - val_loss: 0.4786 - val_accuracy: 0.9000\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 4.4032e-05 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 0.9000\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 4.0919e-05 - accuracy: 1.0000 - val_loss: 0.4848 - val_accuracy: 0.9000\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 4.9139e-05 - accuracy: 1.0000 - val_loss: 0.4880 - val_accuracy: 0.9000\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 4.0436e-05 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.9000\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.8490e-05 - accuracy: 1.0000 - val_loss: 0.4946 - val_accuracy: 0.9000\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.5937e-05 - accuracy: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.9000\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 3.9891e-05 - accuracy: 1.0000 - val_loss: 0.5013 - val_accuracy: 0.9000\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 4.4040e-05 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.9000\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.5022e-05 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.9000\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7034e-05 - accuracy: 1.0000 - val_loss: 0.5114 - val_accuracy: 0.9000\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.6139e-05 - accuracy: 1.0000 - val_loss: 0.5148 - val_accuracy: 0.9000\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.5964e-05 - accuracy: 1.0000 - val_loss: 0.5183 - val_accuracy: 0.9000\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.6584e-05 - accuracy: 1.0000 - val_loss: 0.5219 - val_accuracy: 0.9000\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.4561e-05 - accuracy: 1.0000 - val_loss: 0.5254 - val_accuracy: 0.9000\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.3875e-05 - accuracy: 1.0000 - val_loss: 0.5290 - val_accuracy: 0.9000\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.3847e-05 - accuracy: 1.0000 - val_loss: 0.5326 - val_accuracy: 0.9000\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.2325e-05 - accuracy: 1.0000 - val_loss: 0.5361 - val_accuracy: 0.9000\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.4425e-05 - accuracy: 1.0000 - val_loss: 0.5395 - val_accuracy: 0.9000\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.3249e-05 - accuracy: 1.0000 - val_loss: 0.5429 - val_accuracy: 0.9000\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.8482e-05 - accuracy: 1.0000 - val_loss: 0.5463 - val_accuracy: 0.9000\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.1797e-05 - accuracy: 1.0000 - val_loss: 0.5497 - val_accuracy: 0.9000\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.3356e-05 - accuracy: 1.0000 - val_loss: 0.5532 - val_accuracy: 0.9000\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.3127e-05 - accuracy: 1.0000 - val_loss: 0.5568 - val_accuracy: 0.9000\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.1173e-05 - accuracy: 1.0000 - val_loss: 0.5604 - val_accuracy: 0.9000\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2.9952e-05 - accuracy: 1.0000 - val_loss: 0.5640 - val_accuracy: 0.9000\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 2.8644e-05 - accuracy: 1.0000 - val_loss: 0.5678 - val_accuracy: 0.9000\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 2.8845e-05 - accuracy: 1.0000 - val_loss: 0.5715 - val_accuracy: 0.9000\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.0922e-05 - accuracy: 1.0000 - val_loss: 0.5754 - val_accuracy: 0.9000\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 2.8426e-05 - accuracy: 1.0000 - val_loss: 0.5792 - val_accuracy: 0.9000\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.0461e-05 - accuracy: 1.0000 - val_loss: 0.5831 - val_accuracy: 0.9000\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.7171e-05 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 2.3491e-05 - accuracy: 1.0000 - val_loss: 0.5910 - val_accuracy: 0.9000\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.9991e-05 - accuracy: 1.0000 - val_loss: 0.5950 - val_accuracy: 0.9000\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.0238e-05 - accuracy: 1.0000 - val_loss: 0.5990 - val_accuracy: 0.9000\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.6406e-05 - accuracy: 1.0000 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.9340e-05 - accuracy: 1.0000 - val_loss: 0.6072 - val_accuracy: 0.9000\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.9519e-05 - accuracy: 1.0000 - val_loss: 0.6113 - val_accuracy: 0.9000\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 2.0788e-05 - accuracy: 1.0000 - val_loss: 0.6151 - val_accuracy: 0.9000\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 45ms/step - loss: 2.5134e-05 - accuracy: 1.0000 - val_loss: 0.6191 - val_accuracy: 0.9000\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.3477e-05 - accuracy: 1.0000 - val_loss: 0.6230 - val_accuracy: 0.9000\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 2.4228e-05 - accuracy: 1.0000 - val_loss: 0.6269 - val_accuracy: 0.9000\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 2.5316e-05 - accuracy: 1.0000 - val_loss: 0.6308 - val_accuracy: 0.9000\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.9202e-05 - accuracy: 1.0000 - val_loss: 0.6350 - val_accuracy: 0.9000\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.7178e-05 - accuracy: 1.0000 - val_loss: 0.6391 - val_accuracy: 0.9000\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 2.3997e-05 - accuracy: 1.0000 - val_loss: 0.6431 - val_accuracy: 0.9000\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2.3331e-05 - accuracy: 1.0000 - val_loss: 0.6473 - val_accuracy: 0.9000\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 2.3373e-05 - accuracy: 1.0000 - val_loss: 0.6512 - val_accuracy: 0.9000\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2.4086e-05 - accuracy: 1.0000 - val_loss: 0.6552 - val_accuracy: 0.9000\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.6076e-05 - accuracy: 1.0000 - val_loss: 0.6588 - val_accuracy: 0.9000\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2.3082e-05 - accuracy: 1.0000 - val_loss: 0.6623 - val_accuracy: 0.9000\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2.3752e-05 - accuracy: 1.0000 - val_loss: 0.6662 - val_accuracy: 0.9000\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 2.0942e-05 - accuracy: 1.0000 - val_loss: 0.6698 - val_accuracy: 0.9000\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 2.2315e-05 - accuracy: 1.0000 - val_loss: 0.6737 - val_accuracy: 0.9000\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.9319e-05 - accuracy: 1.0000 - val_loss: 0.6777 - val_accuracy: 0.9000\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 2.0949e-05 - accuracy: 1.0000 - val_loss: 0.6817 - val_accuracy: 0.9000\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.7864e-05 - accuracy: 1.0000 - val_loss: 0.6856 - val_accuracy: 0.9000\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 2.0460e-05 - accuracy: 1.0000 - val_loss: 0.6897 - val_accuracy: 0.9000\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 2.0374e-05 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.9000\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.9869e-05 - accuracy: 1.0000 - val_loss: 0.6977 - val_accuracy: 0.9000\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.7301e-05 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.9000\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.9903e-05 - accuracy: 1.0000 - val_loss: 0.7060 - val_accuracy: 0.9000\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.8300e-05 - accuracy: 1.0000 - val_loss: 0.7101 - val_accuracy: 0.9000\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.9567e-05 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.9000\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.9065e-05 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.9000\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 2.2580e-05 - accuracy: 1.0000 - val_loss: 0.7230 - val_accuracy: 0.9000\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.9315e-05 - accuracy: 1.0000 - val_loss: 0.7273 - val_accuracy: 0.9000\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.4720e-05 - accuracy: 1.0000 - val_loss: 0.7317 - val_accuracy: 0.9000\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.7728e-05 - accuracy: 1.0000 - val_loss: 0.7358 - val_accuracy: 0.9000\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.6197e-05 - accuracy: 1.0000 - val_loss: 0.7398 - val_accuracy: 0.9000\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.8288e-05 - accuracy: 1.0000 - val_loss: 0.7440 - val_accuracy: 0.9000\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.8869e-05 - accuracy: 1.0000 - val_loss: 0.7482 - val_accuracy: 0.9000\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.7062e-05 - accuracy: 1.0000 - val_loss: 0.7520 - val_accuracy: 0.9000\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.7098e-05 - accuracy: 1.0000 - val_loss: 0.7559 - val_accuracy: 0.9000\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.7492e-05 - accuracy: 1.0000 - val_loss: 0.7598 - val_accuracy: 0.9000\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.6936e-05 - accuracy: 1.0000 - val_loss: 0.7637 - val_accuracy: 0.9000\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 2.0187e-05 - accuracy: 1.0000 - val_loss: 0.7677 - val_accuracy: 0.9000\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.8271e-05 - accuracy: 1.0000 - val_loss: 0.7716 - val_accuracy: 0.9000\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.7215e-05 - accuracy: 1.0000 - val_loss: 0.7754 - val_accuracy: 0.9000\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.6121e-05 - accuracy: 1.0000 - val_loss: 0.7792 - val_accuracy: 0.9000\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.6526e-05 - accuracy: 1.0000 - val_loss: 0.7831 - val_accuracy: 0.9000\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.5932e-05 - accuracy: 1.0000 - val_loss: 0.7870 - val_accuracy: 0.9000\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.5925e-05 - accuracy: 1.0000 - val_loss: 0.7908 - val_accuracy: 0.9000\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.6781e-05 - accuracy: 1.0000 - val_loss: 0.7946 - val_accuracy: 0.9000\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.3867e-05 - accuracy: 1.0000 - val_loss: 0.7982 - val_accuracy: 0.9000\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.1521e-05 - accuracy: 1.0000 - val_loss: 0.8016 - val_accuracy: 0.9000\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.7818e-05 - accuracy: 1.0000 - val_loss: 0.8054 - val_accuracy: 0.9000\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.9462e-05 - accuracy: 1.0000 - val_loss: 0.8092 - val_accuracy: 0.9000\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.5238e-05 - accuracy: 1.0000 - val_loss: 0.8130 - val_accuracy: 0.9000\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.4781e-05 - accuracy: 1.0000 - val_loss: 0.8167 - val_accuracy: 0.9000\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.5164e-05 - accuracy: 1.0000 - val_loss: 0.8206 - val_accuracy: 0.9000\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.5758e-05 - accuracy: 1.0000 - val_loss: 0.8246 - val_accuracy: 0.9000\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.4574e-05 - accuracy: 1.0000 - val_loss: 0.8283 - val_accuracy: 0.9000\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.3825e-05 - accuracy: 1.0000 - val_loss: 0.8323 - val_accuracy: 0.9000\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.4547e-05 - accuracy: 1.0000 - val_loss: 0.8361 - val_accuracy: 0.9000\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1641e-05 - accuracy: 1.0000 - val_loss: 0.8397 - val_accuracy: 0.9000\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.4807e-05 - accuracy: 1.0000 - val_loss: 0.8439 - val_accuracy: 0.9000\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.4347e-05 - accuracy: 1.0000 - val_loss: 0.8475 - val_accuracy: 0.9000\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.5279e-05 - accuracy: 1.0000 - val_loss: 0.8514 - val_accuracy: 0.9000\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.3633e-05 - accuracy: 1.0000 - val_loss: 0.8552 - val_accuracy: 0.9000\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.4058e-05 - accuracy: 1.0000 - val_loss: 0.8592 - val_accuracy: 0.9000\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.3359e-05 - accuracy: 1.0000 - val_loss: 0.8628 - val_accuracy: 0.9000\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.6020e-05 - accuracy: 1.0000 - val_loss: 0.8667 - val_accuracy: 0.9000\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.2575e-05 - accuracy: 1.0000 - val_loss: 0.8704 - val_accuracy: 0.9000\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.3905e-05 - accuracy: 1.0000 - val_loss: 0.8738 - val_accuracy: 0.9000\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.4288e-05 - accuracy: 1.0000 - val_loss: 0.8776 - val_accuracy: 0.9000\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.3542e-05 - accuracy: 1.0000 - val_loss: 0.8810 - val_accuracy: 0.9000\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.3572e-05 - accuracy: 1.0000 - val_loss: 0.8846 - val_accuracy: 0.9000\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.3206e-05 - accuracy: 1.0000 - val_loss: 0.8882 - val_accuracy: 0.9000\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.3294e-05 - accuracy: 1.0000 - val_loss: 0.8918 - val_accuracy: 0.9000\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.0503e-05 - accuracy: 1.0000 - val_loss: 0.8952 - val_accuracy: 0.9000\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1855e-05 - accuracy: 1.0000 - val_loss: 0.8986 - val_accuracy: 0.9000\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.2622e-05 - accuracy: 1.0000 - val_loss: 0.9021 - val_accuracy: 0.9000\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.3664e-05 - accuracy: 1.0000 - val_loss: 0.9060 - val_accuracy: 0.9000\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1435e-05 - accuracy: 1.0000 - val_loss: 0.9099 - val_accuracy: 0.9000\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 9.8398e-06 - accuracy: 1.0000 - val_loss: 0.9137 - val_accuracy: 0.9000\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1950e-05 - accuracy: 1.0000 - val_loss: 0.9172 - val_accuracy: 0.9000\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1495e-05 - accuracy: 1.0000 - val_loss: 0.9207 - val_accuracy: 0.9000\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1412e-05 - accuracy: 1.0000 - val_loss: 0.9235 - val_accuracy: 0.9000\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.3255e-05 - accuracy: 1.0000 - val_loss: 0.9272 - val_accuracy: 0.9000\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 8.8188e-06 - accuracy: 1.0000 - val_loss: 0.9311 - val_accuracy: 0.9000\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.2191e-05 - accuracy: 1.0000 - val_loss: 0.9341 - val_accuracy: 0.9000\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1480e-05 - accuracy: 1.0000 - val_loss: 0.9373 - val_accuracy: 0.9000\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0619e-05 - accuracy: 1.0000 - val_loss: 0.9402 - val_accuracy: 0.9000\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1386e-05 - accuracy: 1.0000 - val_loss: 0.9438 - val_accuracy: 0.9000\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.0916e-05 - accuracy: 1.0000 - val_loss: 0.9468 - val_accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "# define callback to save best model\n",
    "checkpoint_filepath = './best_model/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "# store training histroy in history\n",
    "history = model.fit(    \n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    validation_data=(x_test, y_test), \n",
    "    callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64ea3d7",
   "metadata": {},
   "source": [
    "### Training and validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c19dce82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "Best training accuracy of:  1.0  at:  0\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Best validation accuracy of:  0.8999999761581421  at:  0\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "best_acc = max(history.history['accuracy'])\n",
    "best_epoch_acc = history.history['accuracy'].index(best_acc)\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"Best training accuracy of: \", best_acc, \" at: \", best_epoch_acc)\n",
    "print()\n",
    "\n",
    "best_val = max(history.history['val_accuracy'])\n",
    "best_epoch = history.history['val_accuracy'].index(best_val)\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"Best validation accuracy of: \", best_val, \" at: \", best_epoch)\n",
    "print()\n",
    "\n",
    "# plot training history\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# plot history for accuracy\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "\n",
    "# plot history for loss\n",
    "plt.subplot(212)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b1dd2d",
   "metadata": {},
   "source": [
    "### F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7781e230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "Confusion Matrix: \n",
      " [[18  0]\n",
      " [ 2  0]]\n",
      "Accuracy :\n",
      "  90.0\n",
      "F1 :\n",
      "  0.4736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Ignore warning: https://stackoverflow.com/questions/43162506/undefinedmetricwarning-f-score-is-ill-defined-and-being-set-to-0-0-in-labels-wi\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "\n",
    "# Function to transform y_pred to binary \n",
    "def prob_to_pred(y_pred): \n",
    "    result = [] \n",
    "    for i in y_pred: \n",
    "        if i[0] >= 0.5: \n",
    "            result.append(1) \n",
    "        else: \n",
    "            result.append(0) \n",
    "    return np.array(result)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def cal_accuracy(y_test, y_pred):\n",
    "      \n",
    "    print(\"Confusion Matrix: \\n\",\n",
    "        confusion_matrix(y_test, y_pred))\n",
    "      \n",
    "    print (\"Accuracy :\\n \",\n",
    "    accuracy_score(y_test,y_pred)*100)\n",
    "      \n",
    "    print(\"F1 :\\n \",\n",
    "    f1_score(y_test, y_pred, average='macro'))\n",
    "    \n",
    "# get prediction    \n",
    "y_pred = model.predict(x_test)\n",
    "# convert y_pred\n",
    "y_pred = prob_to_pred(y_pred)\n",
    "# print accuracy\n",
    "cal_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3527de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
